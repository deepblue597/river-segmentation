{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3ec86b4-27a6-453f-829f-fd2605e6310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05d992b7-5c72-46c2-b182-f58454ed428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f6da2ae-f840-475f-bfdb-6ff2c76407e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.8), please consider upgrading to the latest version (0.3.12).\n",
      "Path to dataset files: /home/jovyan/.cache/kagglehub/datasets/gvclsu/water-segmentation-dataset/versions/4\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"gvclsu/water-segmentation-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7abc2db3-2a15-4efa-bf9e-fc1c61d60910",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = os.path.join(path,\"water_v2\", \"water_v2\", \"JPEGImages\")\n",
    "mask_dir = os.path.join(path,\"water_v2\", \"water_v2\", \"Annotations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09b6ea72-2a01-4c22-85aa-e51193a92244",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = os.path.join(path,\"water_v2\", \"water_v2\", \"JPEGImages\" , 'ADE20K')\n",
    "mask_dir = os.path.join(path,\"water_v2\", \"water_v2\", \"Annotations\" , 'ADE20K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c50a39c2-130b-4c51-b241-45600ce20dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: Dataset class ---\n",
    "class WaterSegmentationDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.img_names = sorted(os.listdir(img_dir))\n",
    "        self.mask_names = sorted(os.listdir(mask_dir))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_names[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.mask_names[idx])\n",
    "\n",
    "        image = np.array(Image.open(img_path).convert(\"L\"))\n",
    "        mask = np.array(Image.open(mask_path).convert(\"L\"))\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented[\"image\"]\n",
    "            mask = augmented[\"mask\"]\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d81d3d4-3a88-45e9-8587-17175156e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Transforms ---\n",
    "transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f57a3b90-0a6e-4cdb-9046-833084dc9584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 5: Setup Dataset and DataLoader ---\n",
    "train_dataset = WaterSegmentationDataset(img_dir=img_dir, mask_dir=mask_dir, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "00e83953-1ad5-4a61-9bb6-0dae06841162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleList(\n",
       "      (0): UnetDecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): UnetDecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): UnetDecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): UnetDecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): UnetDecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Step 6: Model, loss, optimizer ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=1,\n",
    "    classes=1,\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53444031-4965-44c3-afd4-49a15a4730c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b623f851-0419-487c-acc7-844d1f5240ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "52e24f60-20a7-4342-baf6-e782731c62fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Images processed: 104, Average Loss: 0.7833\n",
      "Epoch [1/10], Images processed: 104, Average Loss: 0.6719\n",
      "Epoch [1/10], Images processed: 104, Average Loss: 0.5633\n",
      "Epoch [1/10], Images processed: 104, Average Loss: 0.5088\n",
      "Epoch [1/10], Images processed: 104, Average Loss: 0.4953\n",
      "Epoch [1/10], Images processed: 104, Average Loss: 0.4827\n",
      "Epoch [1/10], Images processed: 104, Average Loss: 0.4459\n",
      "Epoch [1/10], Images processed: 104, Average Loss: 0.4459\n",
      "Epoch [1/10], Images processed: 104, Average Loss: 0.4502\n",
      "Epoch [1/10], Images processed: 104, Average Loss: 0.4205\n",
      "Epoch [1/10], Images processed: 104, Average Loss: 0.3831\n",
      "Epoch [1/10], Images processed: 104, Average Loss: 0.3775\n",
      "Epoch [1/10], Images processed: 104, Average Loss: 0.3852\n",
      "Epoch [1/10], Images processed: 104, Average Loss: 0.3710\n",
      "Epoch [1/10], Images processed: 104, Average Loss: 0.3758\n",
      "Epoch [1/10], Images processed: 104, Average Loss: 0.3671\n",
      "Epoch [1/10], Images processed: 104, Average Loss: 0.3585\n",
      "Epoch [1/10], Images processed: 104, Average Loss: 0.3609\n",
      "Epoch [1/10], Images processed: 16, Average Loss: 0.3472\n",
      "Epoch [2/10], Images processed: 104, Average Loss: 0.3268\n",
      "Epoch [2/10], Images processed: 104, Average Loss: 0.2990\n",
      "Epoch [2/10], Images processed: 104, Average Loss: 0.2936\n",
      "Epoch [2/10], Images processed: 104, Average Loss: 0.3144\n",
      "Epoch [2/10], Images processed: 104, Average Loss: 0.3062\n",
      "Epoch [2/10], Images processed: 104, Average Loss: 0.2921\n",
      "Epoch [2/10], Images processed: 104, Average Loss: 0.3102\n",
      "Epoch [2/10], Images processed: 104, Average Loss: 0.3073\n",
      "Epoch [2/10], Images processed: 104, Average Loss: 0.3000\n",
      "Epoch [2/10], Images processed: 104, Average Loss: 0.3112\n",
      "Epoch [2/10], Images processed: 104, Average Loss: 0.3092\n",
      "Epoch [2/10], Images processed: 104, Average Loss: 0.2800\n",
      "Epoch [2/10], Images processed: 104, Average Loss: 0.2852\n",
      "Epoch [2/10], Images processed: 104, Average Loss: 0.2725\n",
      "Epoch [2/10], Images processed: 104, Average Loss: 0.2618\n",
      "Epoch [2/10], Images processed: 104, Average Loss: 0.2843\n",
      "Epoch [2/10], Images processed: 104, Average Loss: 0.2788\n",
      "Epoch [2/10], Images processed: 104, Average Loss: 0.2719\n",
      "Epoch [2/10], Images processed: 16, Average Loss: 0.2356\n",
      "Epoch [3/10], Images processed: 104, Average Loss: 0.2345\n",
      "Epoch [3/10], Images processed: 104, Average Loss: 0.2248\n",
      "Epoch [3/10], Images processed: 104, Average Loss: 0.2438\n",
      "Epoch [3/10], Images processed: 104, Average Loss: 0.2228\n",
      "Epoch [3/10], Images processed: 104, Average Loss: 0.2462\n",
      "Epoch [3/10], Images processed: 104, Average Loss: 0.2293\n",
      "Epoch [3/10], Images processed: 104, Average Loss: 0.2238\n",
      "Epoch [3/10], Images processed: 104, Average Loss: 0.2382\n",
      "Epoch [3/10], Images processed: 104, Average Loss: 0.2013\n",
      "Epoch [3/10], Images processed: 104, Average Loss: 0.2075\n",
      "Epoch [3/10], Images processed: 104, Average Loss: 0.2278\n",
      "Epoch [3/10], Images processed: 104, Average Loss: 0.2091\n",
      "Epoch [3/10], Images processed: 104, Average Loss: 0.2263\n",
      "Epoch [3/10], Images processed: 104, Average Loss: 0.2220\n",
      "Epoch [3/10], Images processed: 104, Average Loss: 0.2333\n",
      "Epoch [3/10], Images processed: 104, Average Loss: 0.2208\n",
      "Epoch [3/10], Images processed: 104, Average Loss: 0.2052\n",
      "Epoch [3/10], Images processed: 104, Average Loss: 0.2132\n",
      "Epoch [3/10], Images processed: 16, Average Loss: 0.1955\n",
      "Epoch [4/10], Images processed: 104, Average Loss: 0.1738\n",
      "Epoch [4/10], Images processed: 104, Average Loss: 0.2106\n",
      "Epoch [4/10], Images processed: 104, Average Loss: 0.1693\n",
      "Epoch [4/10], Images processed: 104, Average Loss: 0.1760\n",
      "Epoch [4/10], Images processed: 104, Average Loss: 0.1788\n",
      "Epoch [4/10], Images processed: 104, Average Loss: 0.1783\n",
      "Epoch [4/10], Images processed: 104, Average Loss: 0.1710\n",
      "Epoch [4/10], Images processed: 104, Average Loss: 0.1695\n",
      "Epoch [4/10], Images processed: 104, Average Loss: 0.1776\n",
      "Epoch [4/10], Images processed: 104, Average Loss: 0.2122\n",
      "Epoch [4/10], Images processed: 104, Average Loss: 0.2160\n",
      "Epoch [4/10], Images processed: 104, Average Loss: 0.2119\n",
      "Epoch [4/10], Images processed: 104, Average Loss: 0.2372\n",
      "Epoch [4/10], Images processed: 104, Average Loss: 0.1920\n",
      "Epoch [4/10], Images processed: 104, Average Loss: 0.1938\n",
      "Epoch [4/10], Images processed: 104, Average Loss: 0.1833\n",
      "Epoch [4/10], Images processed: 104, Average Loss: 0.1972\n",
      "Epoch [4/10], Images processed: 104, Average Loss: 0.2016\n",
      "Epoch [4/10], Images processed: 16, Average Loss: 0.1892\n",
      "Epoch [5/10], Images processed: 104, Average Loss: 0.1696\n",
      "Epoch [5/10], Images processed: 104, Average Loss: 0.1720\n",
      "Epoch [5/10], Images processed: 104, Average Loss: 0.1410\n",
      "Epoch [5/10], Images processed: 104, Average Loss: 0.1513\n",
      "Epoch [5/10], Images processed: 104, Average Loss: 0.1373\n",
      "Epoch [5/10], Images processed: 104, Average Loss: 0.1983\n",
      "Epoch [5/10], Images processed: 104, Average Loss: 0.1514\n",
      "Epoch [5/10], Images processed: 104, Average Loss: 0.1496\n",
      "Epoch [5/10], Images processed: 104, Average Loss: 0.1523\n",
      "Epoch [5/10], Images processed: 104, Average Loss: 0.1504\n",
      "Epoch [5/10], Images processed: 104, Average Loss: 0.1845\n",
      "Epoch [5/10], Images processed: 104, Average Loss: 0.1538\n",
      "Epoch [5/10], Images processed: 104, Average Loss: 0.1493\n",
      "Epoch [5/10], Images processed: 104, Average Loss: 0.1437\n",
      "Epoch [5/10], Images processed: 104, Average Loss: 0.1436\n",
      "Epoch [5/10], Images processed: 104, Average Loss: 0.1359\n",
      "Epoch [5/10], Images processed: 104, Average Loss: 0.1402\n",
      "Epoch [5/10], Images processed: 104, Average Loss: 0.1727\n",
      "Epoch [5/10], Images processed: 16, Average Loss: 0.1654\n",
      "Epoch [6/10], Images processed: 104, Average Loss: 0.1513\n",
      "Epoch [6/10], Images processed: 104, Average Loss: 0.1298\n",
      "Epoch [6/10], Images processed: 104, Average Loss: 0.1348\n",
      "Epoch [6/10], Images processed: 104, Average Loss: 0.1369\n",
      "Epoch [6/10], Images processed: 104, Average Loss: 0.1326\n",
      "Epoch [6/10], Images processed: 104, Average Loss: 0.1287\n",
      "Epoch [6/10], Images processed: 104, Average Loss: 0.1308\n",
      "Epoch [6/10], Images processed: 104, Average Loss: 0.1402\n",
      "Epoch [6/10], Images processed: 104, Average Loss: 0.1438\n",
      "Epoch [6/10], Images processed: 104, Average Loss: 0.1328\n",
      "Epoch [6/10], Images processed: 104, Average Loss: 0.1191\n",
      "Epoch [6/10], Images processed: 104, Average Loss: 0.1410\n",
      "Epoch [6/10], Images processed: 104, Average Loss: 0.1412\n",
      "Epoch [6/10], Images processed: 104, Average Loss: 0.1330\n",
      "Epoch [6/10], Images processed: 104, Average Loss: 0.1362\n",
      "Epoch [6/10], Images processed: 104, Average Loss: 0.1422\n",
      "Epoch [6/10], Images processed: 104, Average Loss: 0.1609\n",
      "Epoch [6/10], Images processed: 104, Average Loss: 0.1331\n",
      "Epoch [6/10], Images processed: 16, Average Loss: 0.1153\n",
      "Epoch [7/10], Images processed: 104, Average Loss: 0.1070\n",
      "Epoch [7/10], Images processed: 104, Average Loss: 0.1211\n",
      "Epoch [7/10], Images processed: 104, Average Loss: 0.1105\n",
      "Epoch [7/10], Images processed: 104, Average Loss: 0.1184\n",
      "Epoch [7/10], Images processed: 104, Average Loss: 0.1092\n",
      "Epoch [7/10], Images processed: 104, Average Loss: 0.1316\n",
      "Epoch [7/10], Images processed: 104, Average Loss: 0.1379\n",
      "Epoch [7/10], Images processed: 104, Average Loss: 0.1405\n",
      "Epoch [7/10], Images processed: 104, Average Loss: 0.1139\n",
      "Epoch [7/10], Images processed: 104, Average Loss: 0.1241\n",
      "Epoch [7/10], Images processed: 104, Average Loss: 0.1305\n",
      "Epoch [7/10], Images processed: 104, Average Loss: 0.1290\n",
      "Epoch [7/10], Images processed: 104, Average Loss: 0.1072\n",
      "Epoch [7/10], Images processed: 104, Average Loss: 0.1466\n",
      "Epoch [7/10], Images processed: 104, Average Loss: 0.1357\n",
      "Epoch [7/10], Images processed: 104, Average Loss: 0.1137\n",
      "Epoch [7/10], Images processed: 104, Average Loss: 0.1276\n",
      "Epoch [7/10], Images processed: 104, Average Loss: 0.1177\n",
      "Epoch [7/10], Images processed: 16, Average Loss: 0.1237\n",
      "Epoch [8/10], Images processed: 104, Average Loss: 0.1051\n",
      "Epoch [8/10], Images processed: 104, Average Loss: 0.1035\n",
      "Epoch [8/10], Images processed: 104, Average Loss: 0.1136\n",
      "Epoch [8/10], Images processed: 104, Average Loss: 0.1077\n",
      "Epoch [8/10], Images processed: 104, Average Loss: 0.1091\n",
      "Epoch [8/10], Images processed: 104, Average Loss: 0.1092\n",
      "Epoch [8/10], Images processed: 104, Average Loss: 0.1076\n",
      "Epoch [8/10], Images processed: 104, Average Loss: 0.1043\n",
      "Epoch [8/10], Images processed: 104, Average Loss: 0.1054\n",
      "Epoch [8/10], Images processed: 104, Average Loss: 0.0964\n",
      "Epoch [8/10], Images processed: 104, Average Loss: 0.1135\n",
      "Epoch [8/10], Images processed: 104, Average Loss: 0.1050\n",
      "Epoch [8/10], Images processed: 104, Average Loss: 0.1326\n",
      "Epoch [8/10], Images processed: 104, Average Loss: 0.1121\n",
      "Epoch [8/10], Images processed: 104, Average Loss: 0.1040\n",
      "Epoch [8/10], Images processed: 104, Average Loss: 0.1134\n",
      "Epoch [8/10], Images processed: 104, Average Loss: 0.1300\n",
      "Epoch [8/10], Images processed: 104, Average Loss: 0.1235\n",
      "Epoch [8/10], Images processed: 16, Average Loss: 0.1017\n",
      "Epoch [9/10], Images processed: 104, Average Loss: 0.1523\n",
      "Epoch [9/10], Images processed: 104, Average Loss: 0.1364\n",
      "Epoch [9/10], Images processed: 104, Average Loss: 0.0998\n",
      "Epoch [9/10], Images processed: 104, Average Loss: 0.1000\n",
      "Epoch [9/10], Images processed: 104, Average Loss: 0.1039\n",
      "Epoch [9/10], Images processed: 104, Average Loss: 0.1039\n",
      "Epoch [9/10], Images processed: 104, Average Loss: 0.0954\n",
      "Epoch [9/10], Images processed: 104, Average Loss: 0.0903\n",
      "Epoch [9/10], Images processed: 104, Average Loss: 0.0969\n",
      "Epoch [9/10], Images processed: 104, Average Loss: 0.0966\n",
      "Epoch [9/10], Images processed: 104, Average Loss: 0.0897\n",
      "Epoch [9/10], Images processed: 104, Average Loss: 0.0924\n",
      "Epoch [9/10], Images processed: 104, Average Loss: 0.0929\n",
      "Epoch [9/10], Images processed: 104, Average Loss: 0.0944\n",
      "Epoch [9/10], Images processed: 104, Average Loss: 0.0914\n",
      "Epoch [9/10], Images processed: 104, Average Loss: 0.0883\n",
      "Epoch [9/10], Images processed: 104, Average Loss: 0.0863\n",
      "Epoch [9/10], Images processed: 104, Average Loss: 0.0927\n",
      "Epoch [9/10], Images processed: 16, Average Loss: 0.0718\n",
      "Epoch [10/10], Images processed: 104, Average Loss: 0.0858\n",
      "Epoch [10/10], Images processed: 104, Average Loss: 0.0799\n",
      "Epoch [10/10], Images processed: 104, Average Loss: 0.1005\n",
      "Epoch [10/10], Images processed: 104, Average Loss: 0.1087\n",
      "Epoch [10/10], Images processed: 104, Average Loss: 0.1006\n",
      "Epoch [10/10], Images processed: 104, Average Loss: 0.0856\n",
      "Epoch [10/10], Images processed: 104, Average Loss: 0.0956\n",
      "Epoch [10/10], Images processed: 104, Average Loss: 0.0921\n",
      "Epoch [10/10], Images processed: 104, Average Loss: 0.1174\n",
      "Epoch [10/10], Images processed: 104, Average Loss: 0.1106\n",
      "Epoch [10/10], Images processed: 104, Average Loss: 0.0912\n",
      "Epoch [10/10], Images processed: 104, Average Loss: 0.0898\n",
      "Epoch [10/10], Images processed: 104, Average Loss: 0.0814\n",
      "Epoch [10/10], Images processed: 104, Average Loss: 0.0877\n",
      "Epoch [10/10], Images processed: 104, Average Loss: 0.0912\n",
      "Epoch [10/10], Images processed: 104, Average Loss: 0.0910\n",
      "Epoch [10/10], Images processed: 104, Average Loss: 0.1360\n",
      "Epoch [10/10], Images processed: 104, Average Loss: 0.1163\n",
      "Epoch [10/10], Images processed: 16, Average Loss: 0.1189\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "print_every = 100  # print after this many images\n",
    "image_count = 0    # count of images processed so far\n",
    "\n",
    "for epoch in range(10):\n",
    "    epoch_loss = 0.0\n",
    "    for images, masks in train_loader:\n",
    "        images = images.to(device)\n",
    "        masks = masks.float().unsqueeze(1).to(device) / 255.0\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_size = images.size(0)  # number of images in the current batch\n",
    "        image_count += batch_size\n",
    "        epoch_loss += loss.item() * batch_size  # multiply loss by batch size to weight average\n",
    "\n",
    "        if image_count >= print_every:\n",
    "            avg_loss = epoch_loss / image_count\n",
    "            print(f\"Epoch [{epoch+1}/10], Images processed: {image_count}, Average Loss: {avg_loss:.4f}\")\n",
    "            image_count = 0\n",
    "            epoch_loss = 0.0\n",
    "\n",
    "    # If leftover images after loop ends (less than print_every)\n",
    "    if image_count > 0:\n",
    "        avg_loss = epoch_loss / image_count\n",
    "        print(f\"Epoch [{epoch+1}/10], Images processed: {image_count}, Average Loss: {avg_loss:.4f}\")\n",
    "        image_count = 0\n",
    "        epoch_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cbc273-60f3-4379-a4b8-02b67c608148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "river-seg",
   "language": "python",
   "name": "river-seg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
